{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ea24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731ccebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da10ff02691f4369bcbb8d6304482b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac49f5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Generate:\n",
      "<s><s> [INST] Explain Heise Zeitschriftenverlag [/INST]\n",
      "\n",
      "Heise Zeitschriftenverlag is a leading German publishing company that specializes in technology, science, and digital media. The company was founded in 1991 by Hans-Werner Heise and is headquartered in Hannover, Germany. Heise Zeitschriftenverlag publishes a wide range of print and digital media, including magazines, books, and online platforms.\n",
      "\n",
      "One of the most notable products of Heise Zeitschriftenverlag is the computer magazine \"c't,\" which is one of the most popular and influential technology magazines in Germany. The magazine covers various topics related to computers, software, and technology, and is known for its high-quality technical articles, reviews, and tests. Heise Zeitschriftenverlag also publishes other technology magazines such as \"iX,\" \"chip,\" and \"IT-Z.\"\n",
      "\n",
      "The company's online platforms include heise.de, which is one of the most visited technology websites in Germany. Heise.de offers news, reviews, and articles on technology, science, and digital media. The website also includes forums, a download area, and a database of software and drivers.\n",
      "\n",
      "Heise Zeitschriftenverlag also offers a range of books on technology, science, and digital media. These books are published under the imprint \"Heise Verlag\" and cover various topics, including programming, software development, security, and digital media.\n",
      "\n",
      "Heise Zeitschriftenverlag has a strong focus on quality and innovation, and is known for its expert editors and high-quality content. The company has won numerous awards for its publications and online platforms, including the German Media Award, the European Digital Media Award, and the Webby Award.\n",
      "\n",
      "In summary, Heise Zeitschriftenverlag is a leading German publishing company that specializes in technology, science, and digital media. The company publishes magazines, books, and online platforms on various topics related to these fields, and is known for its high-quality content and expertise.</s>\n",
      "CPU times: user 9.85 s, sys: 11.8 ms, total: 9.86 s\n",
      "Wall time: 9.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"Explain Heise Zeitschriftenverlag\"\n",
    "prompt_template=f'''<s>[INST] {prompt} [/INST]\n",
    "'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3cbc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 27 11:59:50 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:26:00.0 Off |                  Off |\r\n",
      "|  0%   44C    P8              31W / 450W |  15206MiB / 24564MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A   3932713      C   .../cwinkler/.venv/jupyter/bin/python3    15196MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dada14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
